{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-10-25T05:41:30.554241Z",
     "iopub.status.busy": "2020-10-25T05:41:30.553498Z",
     "iopub.status.idle": "2020-10-25T05:41:30.796973Z",
     "shell.execute_reply": "2020-10-25T05:41:30.795857Z"
    },
    "papermill": {
     "duration": 0.285414,
     "end_time": "2020-10-25T05:41:30.797113",
     "exception": false,
     "start_time": "2020-10-25T05:41:30.511699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "from glob import glob\n",
    "from keras.utils import to_categorical\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.applications import ResNet50\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import copy\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.040149,
     "end_time": "2020-10-25T05:41:30.876391",
     "exception": false,
     "start_time": "2020-10-25T05:41:30.836242",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Image Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-10-25T05:41:30.954846Z",
     "iopub.status.busy": "2020-10-25T05:41:30.954090Z",
     "iopub.status.idle": "2020-10-25T05:41:31.238524Z",
     "shell.execute_reply": "2020-10-25T05:41:31.237623Z"
    },
    "papermill": {
     "duration": 0.324605,
     "end_time": "2020-10-25T05:41:31.238656",
     "exception": false,
     "start_time": "2020-10-25T05:41:30.914051",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "images_path = '../Images/'\n",
    "images = glob(images_path+'*.jpg')\n",
    "print(\"No. of Images: \", len(images))\n",
    "print(\"List View: \", images[:5])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-25T05:41:31.410399Z",
     "iopub.status.busy": "2020-10-25T05:41:31.409641Z",
     "iopub.status.idle": "2020-10-25T05:41:32.617420Z",
     "shell.execute_reply": "2020-10-25T05:41:32.617974Z"
    },
    "papermill": {
     "duration": 1.256596,
     "end_time": "2020-10-25T05:41:32.618126",
     "exception": false,
     "start_time": "2020-10-25T05:41:31.361530",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for i in range(5):\n",
    "plt.figure()\n",
    "img = cv2.imread(images[0])\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model for Feature Extraction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-25T05:41:32.738626Z",
     "iopub.status.busy": "2020-10-25T05:41:32.737933Z",
     "iopub.status.idle": "2020-10-25T05:41:44.360465Z",
     "shell.execute_reply": "2020-10-25T05:41:44.359211Z"
    },
    "papermill": {
     "duration": 11.683826,
     "end_time": "2020-10-25T05:41:44.360603",
     "exception": false,
     "start_time": "2020-10-25T05:41:32.676777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_model = ResNet50(include_top=True)\n",
    "base_model.summary()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-25T05:41:44.494553Z",
     "iopub.status.busy": "2020-10-25T05:41:44.493824Z",
     "iopub.status.idle": "2020-10-25T05:41:44.586880Z",
     "shell.execute_reply": "2020-10-25T05:41:44.586042Z"
    },
    "papermill": {
     "duration": 0.161685,
     "end_time": "2020-10-25T05:41:44.587036",
     "exception": false,
     "start_time": "2020-10-25T05:41:44.425351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "last = base_model.layers[-2].output\n",
    "main_model = Model(inputs=base_model.input, outputs=last)\n",
    "main_model.summary()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-25T05:41:44.737106Z",
     "iopub.status.busy": "2020-10-25T05:41:44.736018Z",
     "iopub.status.idle": "2020-10-25T05:43:14.924155Z",
     "shell.execute_reply": "2020-10-25T05:43:14.922901Z"
    },
    "papermill": {
     "duration": 90.259706,
     "end_time": "2020-10-25T05:43:14.924281",
     "exception": false,
     "start_time": "2020-10-25T05:41:44.664575",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "images_features = {}\n",
    "model_type = 'resnet50'\n",
    "SAVE = 'features_'+model_type+'.joblib'\n",
    "\n",
    "if os.path.exists(SAVE):\n",
    "    images_features = joblib.load(SAVE)\n",
    "else:\n",
    "    for i in images:\n",
    "        img = cv2.imread(i)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (224, 224))\n",
    "        img = img.reshape(1, 224, 224, 3)\n",
    "        pred = main_model.predict(img).reshape(2048,)\n",
    "        img_name = i.split('\\\\')[-1]\n",
    "        images_features[img_name] = pred\n",
    "\n",
    "    joblib.dump(images_features, SAVE)\n",
    "\n",
    "print(\"Number of Features: \", len(images_features))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.071863,
     "end_time": "2020-10-25T05:43:15.226531",
     "exception": false,
     "start_time": "2020-10-25T05:43:15.154668",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-25T05:43:15.380631Z",
     "iopub.status.busy": "2020-10-25T05:43:15.379968Z",
     "iopub.status.idle": "2020-10-25T05:43:15.384882Z",
     "shell.execute_reply": "2020-10-25T05:43:15.384059Z"
    },
    "papermill": {
     "duration": 0.083779,
     "end_time": "2020-10-25T05:43:15.384999",
     "exception": false,
     "start_time": "2020-10-25T05:43:15.301220",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "caption_path = '../captions.txt'\n",
    "captions = open(caption_path, 'rb').read().decode('utf-8').split('\\n')\n",
    "print(\"No. of Captions: \", len(captions))\n",
    "print(captions[1].split(',')[1])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map Images to Captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-25T05:43:15.961669Z",
     "iopub.status.busy": "2020-10-25T05:43:15.935825Z",
     "iopub.status.idle": "2020-10-25T05:43:15.980014Z",
     "shell.execute_reply": "2020-10-25T05:43:15.979334Z"
    },
    "papermill": {
     "duration": 0.140746,
     "end_time": "2020-10-25T05:43:15.980129",
     "exception": false,
     "start_time": "2020-10-25T05:43:15.839383",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "captions_dict = {}\n",
    "# reference_dict = copy.deepcopy(captions_dict)\n",
    "for i in captions:\n",
    "    try:\n",
    "        img_name = i.split(',')[0]\n",
    "        caption = i.split(',')[1]\n",
    "        if img_name in images_features:\n",
    "            if img_name not in captions_dict:\n",
    "                captions_dict[img_name] = [caption]\n",
    "            else:\n",
    "                captions_dict[img_name].append(caption)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "reference_dict = copy.deepcopy(captions_dict)\n",
    "len(captions_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in reference_dict.items():\n",
    "    for x in range(len(reference_dict[k])):\n",
    "        reference_dict[k][x] = reference_dict[k][x].split()\n",
    "# reference_dict['Images\\\\1000268201_693b08cb0e.jpg']\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.076594,
     "end_time": "2020-10-25T05:43:16.293608",
     "exception": false,
     "start_time": "2020-10-25T05:43:16.217014",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Visualize Images with Captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-25T05:43:18.180315Z",
     "iopub.status.busy": "2020-10-25T05:43:18.179253Z",
     "iopub.status.idle": "2020-10-25T05:43:18.417396Z",
     "shell.execute_reply": "2020-10-25T05:43:18.416834Z"
    },
    "papermill": {
     "duration": 0.341309,
     "end_time": "2020-10-25T05:43:18.417518",
     "exception": false,
     "start_time": "2020-10-25T05:43:18.076209",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for k in images_features.keys():\n",
    "    plt.figure()\n",
    "    img_name = '../Images/' + k\n",
    "    img = cv2.imread(img_name)\n",
    "    print(img_name)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.xlabel(captions_dict[k][-1])\n",
    "    plt.imshow(img)\n",
    "    break\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-25T05:43:18.627909Z",
     "iopub.status.busy": "2020-10-25T05:43:18.627039Z",
     "iopub.status.idle": "2020-10-25T05:43:18.631621Z",
     "shell.execute_reply": "2020-10-25T05:43:18.631039Z"
    },
    "papermill": {
     "duration": 0.113976,
     "end_time": "2020-10-25T05:43:18.631762",
     "exception": false,
     "start_time": "2020-10-25T05:43:18.517786",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocessed(txt):\n",
    "    modified = txt.lower()\n",
    "    modified = 'startofseq ' + modified + ' endofseq'\n",
    "    return modified\n",
    "\n",
    "\n",
    "for k, v in captions_dict.items():\n",
    "    for vv in v:\n",
    "        captions_dict[k][v.index(vv)] = preprocessed(vv)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.10596,
     "end_time": "2020-10-25T05:43:19.067240",
     "exception": false,
     "start_time": "2020-10-25T05:43:18.961280",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Create Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-25T05:43:19.288410Z",
     "iopub.status.busy": "2020-10-25T05:43:19.283325Z",
     "iopub.status.idle": "2020-10-25T05:43:19.321922Z",
     "shell.execute_reply": "2020-10-25T05:43:19.321294Z"
    },
    "papermill": {
     "duration": 0.154361,
     "end_time": "2020-10-25T05:43:19.322043",
     "exception": false,
     "start_time": "2020-10-25T05:43:19.167682",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "count_words = {}\n",
    "for k, vv in captions_dict.items():\n",
    "    for v in vv:\n",
    "        for word in v.split():\n",
    "            if word not in count_words:\n",
    "\n",
    "                count_words[word] = 0\n",
    "\n",
    "            else:\n",
    "                count_words[word] += 1\n",
    "\n",
    "print(\"Vocab Size: \", len(count_words))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Vocabulary to Integer Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-25T05:43:19.753233Z",
     "iopub.status.busy": "2020-10-25T05:43:19.752251Z",
     "iopub.status.idle": "2020-10-25T05:43:19.755248Z",
     "shell.execute_reply": "2020-10-25T05:43:19.754747Z"
    },
    "papermill": {
     "duration": 0.115669,
     "end_time": "2020-10-25T05:43:19.755372",
     "exception": false,
     "start_time": "2020-10-25T05:43:19.639703",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "THRESH = -1\n",
    "count = 1\n",
    "new_dict = {}\n",
    "for k, v in count_words.items():\n",
    "    if count_words[k] > THRESH:\n",
    "        new_dict[k] = count\n",
    "        count += 1\n",
    "\n",
    "print(\"Vocab Size: \", len(new_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-25T05:43:20.914119Z",
     "iopub.status.busy": "2020-10-25T05:43:20.909034Z",
     "iopub.status.idle": "2020-10-25T05:43:20.944952Z",
     "shell.execute_reply": "2020-10-25T05:43:20.944393Z"
    },
    "papermill": {
     "duration": 0.17438,
     "end_time": "2020-10-25T05:43:20.945078",
     "exception": false,
     "start_time": "2020-10-25T05:43:20.770698",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Before: \", captions_dict['1000268201_693b08cb0e.jpg'])\n",
    "new_dict['<OUT>'] = len(new_dict)\n",
    "for k, vv in captions_dict.items():\n",
    "    for v in vv:\n",
    "        encoded = []\n",
    "        for word in v.split():\n",
    "            if word not in new_dict:\n",
    "                encoded.append(new_dict['<OUT>'])\n",
    "            else:\n",
    "                encoded.append(new_dict[word])\n",
    "\n",
    "        captions_dict[k][vv.index(v)] = encoded\n",
    "\n",
    "print(\"After: \", captions_dict['1000268201_693b08cb0e.jpg'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.131971,
     "end_time": "2020-10-25T05:43:23.607242",
     "exception": false,
     "start_time": "2020-10-25T05:43:23.475271",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Generator Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-25T05:43:27.655084Z",
     "iopub.status.busy": "2020-10-25T05:43:27.654092Z",
     "iopub.status.idle": "2020-10-25T05:43:27.657331Z",
     "shell.execute_reply": "2020-10-25T05:43:27.656796Z"
    },
    "papermill": {
     "duration": 0.299513,
     "end_time": "2020-10-25T05:43:27.657439",
     "exception": false,
     "start_time": "2020-10-25T05:43:27.357926",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 0\n",
    "for k, vv in captions_dict.items():\n",
    "    for v in vv:\n",
    "        if len(v) > MAX_LEN:\n",
    "            MAX_LEN = len(v)\n",
    "\n",
    "print(\"Max Length of a Word: \", MAX_LEN)\n",
    "\n",
    "Batch_size = 5000\n",
    "VOCAB_SIZE = len(new_dict)\n",
    "\n",
    "\n",
    "def generator(image_ids, photo, cleaned_captions):\n",
    "    X1 = []\n",
    "    X2 = []\n",
    "    y_out = []\n",
    "\n",
    "    for image_id in image_ids:\n",
    "        captions = cleaned_captions[image_id]\n",
    "        for v in captions:\n",
    "            # for k, caption_list in captions.items():\n",
    "            #     for v in caption_list:\n",
    "            for i in range(1, len(v)):\n",
    "                X1.append(photo[image_id])\n",
    "\n",
    "                in_seq = [v[:i]]\n",
    "                out_seq = v[i]\n",
    "\n",
    "                in_seq = pad_sequences(\n",
    "                    in_seq, maxlen=MAX_LEN, padding='post', truncating='post')[0]\n",
    "                out_seq = to_categorical([out_seq], num_classes=VOCAB_SIZE)[0]\n",
    "\n",
    "                X2.append(in_seq)\n",
    "                y_out.append(out_seq)\n",
    "\n",
    "    return np.array(X1), np.array(X2, dtype='float64'), np.array(y_out, dtype='float64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validation_test_split(descriptions, train_size=0.74, validation_size=0.13):\n",
    "    image_ids = list(descriptions.keys())\n",
    "\n",
    "    train_split = int(len(image_ids) * train_size)\n",
    "    validation_split = int(len(image_ids) * (train_size + validation_size))\n",
    "\n",
    "    train = image_ids[:train_split]\n",
    "    validation = image_ids[train_split:validation_split]\n",
    "    test = image_ids[validation_split:]\n",
    "    return train, validation, test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_id_train, image_id_validation, image_id_test = train_validation_test_split(\n",
    "    captions_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(image_id_train), len(image_id_validation), len(image_id_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-25T05:43:28.001649Z",
     "iopub.status.busy": "2020-10-25T05:43:28.000592Z",
     "iopub.status.idle": "2020-10-25T05:43:32.902514Z",
     "shell.execute_reply": "2020-10-25T05:43:32.901855Z"
    },
    "papermill": {
     "duration": 5.077634,
     "end_time": "2020-10-25T05:43:32.902642",
     "exception": false,
     "start_time": "2020-10-25T05:43:27.825008",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X1_train, X2_train, y_train = generator(\n",
    "    image_id_train, images_features, captions_dict)\n",
    "X1_val, X2_val, y_val = generator(\n",
    "    image_id_validation, images_features, captions_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train.shape, X2_train.shape, y_train.shape, X1_val.shape\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.171174,
     "end_time": "2020-10-25T05:43:36.294434",
     "exception": false,
     "start_time": "2020-10-25T05:43:36.123260",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# RNN Model for Training and Prediction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-25T05:43:36.824717Z",
     "iopub.status.busy": "2020-10-25T05:43:36.823679Z",
     "iopub.status.idle": "2020-10-25T05:43:36.828938Z",
     "shell.execute_reply": "2020-10-25T05:43:36.830118Z"
    },
    "papermill": {
     "duration": 0.274531,
     "end_time": "2020-10-25T05:43:36.830329",
     "exception": false,
     "start_time": "2020-10-25T05:43:36.555798",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import TimeDistributed, Activation, RepeatVector, Concatenate\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-25T05:43:37.555698Z",
     "iopub.status.busy": "2020-10-25T05:43:37.554649Z",
     "iopub.status.idle": "2020-10-25T05:43:38.476738Z",
     "shell.execute_reply": "2020-10-25T05:43:38.475663Z"
    },
    "papermill": {
     "duration": 1.106921,
     "end_time": "2020-10-25T05:43:38.476863",
     "exception": false,
     "start_time": "2020-10-25T05:43:37.369942",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedding_size = 128\n",
    "max_len = MAX_LEN\n",
    "vocab_size = len(new_dict)\n",
    "\n",
    "image_model = Sequential()\n",
    "\n",
    "image_model.add(Dense(embedding_size, input_shape=(2048,), activation='relu'))\n",
    "image_model.add(RepeatVector(max_len))\n",
    "\n",
    "image_model.summary()\n",
    "\n",
    "language_model = Sequential()\n",
    "\n",
    "language_model.add(Embedding(input_dim=vocab_size,\n",
    "                   output_dim=embedding_size, input_length=max_len))\n",
    "language_model.add(LSTM(256, return_sequences=True))\n",
    "language_model.add(TimeDistributed(Dense(embedding_size)))\n",
    "\n",
    "language_model.summary()\n",
    "\n",
    "conca = Concatenate()([image_model.output, language_model.output])\n",
    "x = LSTM(128, return_sequences=True)(conca)\n",
    "x = LSTM(512, return_sequences=False)(x)\n",
    "x = Dense(vocab_size)(x)\n",
    "out = Activation('softmax')(x)\n",
    "model = Model(inputs=[image_model.input, language_model.input], outputs=out)\n",
    "\n",
    "# model.load_weights(\"mine_model_weights.h5\")\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='RMSprop', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, show_shapes=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-25T05:43:38.851818Z",
     "iopub.status.busy": "2020-10-25T05:43:38.850423Z",
     "iopub.status.idle": "2020-10-25T05:55:18.141689Z",
     "shell.execute_reply": "2020-10-25T05:55:18.141069Z"
    },
    "papermill": {
     "duration": 699.488003,
     "end_time": "2020-10-25T05:55:18.141818",
     "exception": false,
     "start_time": "2020-10-25T05:43:38.653815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "EPOCH = 2\n",
    "BATCH_SIZE = 512\n",
    "history = model.fit([X1_train, X2_train], y_train,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCH,\n",
    "                    validation_data=([X1_val, X2_val], y_val))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-25T05:55:25.651322Z",
     "iopub.status.busy": "2020-10-25T05:55:25.649505Z",
     "iopub.status.idle": "2020-10-25T05:55:25.652019Z",
     "shell.execute_reply": "2020-10-25T05:55:25.652561Z"
    },
    "papermill": {
     "duration": 3.631636,
     "end_time": "2020-10-25T05:55:25.652700",
     "exception": false,
     "start_time": "2020-10-25T05:55:22.021064",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "inv_dict = {v: k for k, v in new_dict.items()}  # For Prediction\n",
    "model.save('model_'+model_type+'_'+str(EPOCH)+'E.h5')\n",
    "model.save_weights('mine_model_weights_'+model_type+'_'+str(EPOCH)+'E.h5')\n",
    "np.save('vocab'+model_type+'.npy', new_dict)  # type: ignore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training and test loss histories\n",
    "training_loss = history.history['loss']\n",
    "test_loss = history.history['val_loss']\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "# Visualize loss history\n",
    "plt.plot(epoch_count, training_loss, 'r')\n",
    "plt.plot(epoch_count, test_loss, 'b')\n",
    "plt.legend(['Training Loss', 'Test Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(history.history,'history_'+model_type+str(EPOCH)+'.joblib')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 4.069437,
     "end_time": "2020-10-25T05:56:04.785386",
     "exception": false,
     "start_time": "2020-10-25T05:56:00.715949",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImage(x):\n",
    "\n",
    "    test_img_path = images[x]\n",
    "\n",
    "    test_img = cv2.imread(test_img_path)\n",
    "    test_img = cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    test_img = cv2.resize(test_img, (224, 224))\n",
    "\n",
    "    test_img = np.reshape(test_img, (1, 224, 224, 3))\n",
    "\n",
    "    return test_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-25T05:56:12.326684Z",
     "iopub.status.busy": "2020-10-25T05:56:12.325631Z",
     "iopub.status.idle": "2020-10-25T05:56:18.666813Z",
     "shell.execute_reply": "2020-10-25T05:56:18.667382Z"
    },
    "papermill": {
     "duration": 9.970073,
     "end_time": "2020-10-25T05:56:18.667536",
     "exception": false,
     "start_time": "2020-10-25T05:56:08.697463",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics = {'BLEU-1': [], 'BLEU-2': [], 'BLEU-3': [], 'BLEU-4': []}\n",
    "for i in range(5):\n",
    "    # for i in range(TEST):\n",
    "    #     no = i\n",
    "    no = np.random.randint(1500, 6000, (1, 1))[0, 0]\n",
    "    test_feature = main_model.predict(getImage(no)).reshape(1, 2048)\n",
    "\n",
    "    test_img_path = images[no]\n",
    "    test_img = cv2.imread(test_img_path)\n",
    "    test_img = cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    text_inp = ['startofseq']\n",
    "\n",
    "    count = 0\n",
    "    caption = ''\n",
    "    while count < 40:  # Assuming number of words in a caption is not more than 40\n",
    "        count += 1\n",
    "\n",
    "        encoded = []\n",
    "        for i in text_inp:\n",
    "            encoded.append(new_dict[i])\n",
    "\n",
    "        encoded = [encoded]\n",
    "\n",
    "        encoded = pad_sequences(encoded, padding='post',\n",
    "                                truncating='post', maxlen=MAX_LEN)\n",
    "\n",
    "        # Predicting next word which has Higher Probability\n",
    "        prediction = np.argmax(model.predict([test_feature, encoded]))\n",
    "\n",
    "        sampled_word = inv_dict[prediction]\n",
    "\n",
    "        if sampled_word == 'endofseq':\n",
    "            break\n",
    "\n",
    "        caption = caption + ' ' + sampled_word\n",
    "\n",
    "        text_inp.append(sampled_word)\n",
    "\n",
    "    ref = reference_dict[test_img_path.split('\\\\')[-1]]\n",
    "    metrics['BLEU-1'].append(sentence_bleu(ref,\n",
    "                             caption.split(), weights=(1, 0, 0, 0)))\n",
    "    metrics['BLEU-2'].append(sentence_bleu(ref,\n",
    "                             caption.split(), weights=(0.5, 0.5, 0, 0)))\n",
    "    metrics['BLEU-3'].append(sentence_bleu(ref,\n",
    "                             caption.split(), weights=(0.33, 0.33, 0.33, 0)))\n",
    "    metrics['BLEU-4'].append(sentence_bleu(ref,\n",
    "                             caption.split(), weights=(0.25, 0.25, 0.25, 0.25)))\n",
    "    plt.figure()\n",
    "    plt.imshow(test_img)\n",
    "    plt.xlabel(caption)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "papermill": {
   "duration": 920.593543,
   "end_time": "2020-10-25T05:56:47.084717",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-10-25T05:41:26.491174",
   "version": "2.1.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "f53d944b2b75f961eba6ec6b49ae11eee88bebce38fd8cba5f9c225ee95284a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
